import json
import re

def normalize_arabic(text):
    """ØªÙ†Ø¸ÙŠÙ ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
    if not text:
        return ""
    text = text.lower()
    text = re.sub(r'[\u064B-\u065F]', '', text)  # Ø­Ø°Ù Ø§Ù„ØªØ´ÙƒÙŠÙ„
    text = text.replace('Ø£', 'Ø§').replace('Ø¥', 'Ø§').replace('Ø¢', 'Ø§')
    text = text.replace('Ø©', 'Ù‡')
    text = text.replace('Ù‰', 'ÙŠ')
    return text.strip()

def is_keyword_relevant(keyword, category_name, all_words_in_name):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø© Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø¨Ø§Ù„ØªØµÙ†ÙŠÙ"""
    keyword_norm = normalize_arabic(keyword)
    name_norm = normalize_arabic(category_name)

    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙƒÙ„Ù…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø§Ø³Ù…
    if keyword_norm in name_norm or name_norm in keyword_norm:
        return True

    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø£ÙŠ ÙƒÙ„Ù…Ø© Ù…Ù† Ø§Ù„Ø§Ø³Ù… Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    for word in all_words_in_name:
        word_norm = normalize_arabic(word)
        if len(word_norm) > 2:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
            if word_norm in keyword_norm or keyword_norm in word_norm:
                return True

    return False

def get_category_words(category_name):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ø§Ø³Ù… Ø§Ù„ØªØµÙ†ÙŠÙ"""
    # ÙƒÙ„Ù…Ø§Øª Ø´Ø§Ø¦Ø¹Ø© Ù†ØªØ¬Ø§Ù‡Ù„Ù‡Ø§
    stop_words = ['Ùˆ', 'ÙÙŠ', 'Ù…Ù†', 'Ø¥Ù„Ù‰', 'Ø¹Ù„Ù‰', 'Ø¹Ù†', 'Ø£Ùˆ', 'Ù„', 'Ù„Ù„', 'Ø§Ù„', 'Ø¨Ø§', 'Ø¨', 'the', 'and', 'or', 'of', 'for']

    words = re.split(r'[\sØŒ,\-/]+', category_name)
    return [w for w in words if len(w) > 1 and normalize_arabic(w) not in stop_words]

def validate_and_clean_keywords(input_file, output_file):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙˆØ¥Ø²Ø§Ù„Ø© ØºÙŠØ± Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©"""

    print("ğŸ“– Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù...")
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data)} ØªØµÙ†ÙŠÙ\n")

    total_removed_ar = 0
    total_removed_en = 0
    total_kept_ar = 0
    total_kept_en = 0

    issues = []

    print("ğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©...\n")

    for i, category in enumerate(data):
        if i % 100 == 0:
            print(f"   Ù…Ø¹Ø§Ù„Ø¬Ø© {i}/{len(data)}...")

        name_ar = category.get('name_ar', '')
        name_en = category.get('name_en', '')

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø§Ø³Ù…
        words_ar = get_category_words(name_ar)
        words_en = get_category_words(name_en)

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        if category.get('search_key_words_ar'):
            original_ar = category['search_key_words_ar']

            # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© ÙÙ‚Ø·
            valid_ar = []
            invalid_ar = []

            for kw in original_ar:
                if is_keyword_relevant(kw, name_ar, words_ar):
                    valid_ar.append(kw)
                else:
                    invalid_ar.append(kw)

            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
            category['search_key_words_ar'] = valid_ar

            total_kept_ar += len(valid_ar)
            total_removed_ar += len(invalid_ar)

            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø¥Ø°Ø§ ØªÙ… Ø­Ø°Ù Ø§Ù„ÙƒØ«ÙŠØ±
            if invalid_ar and len(invalid_ar) > len(original_ar) * 0.5:
                issues.append({
                    'id': category.get('id'),
                    'name_ar': name_ar,
                    'removed': invalid_ar[:5],  # Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª Ù…Ø­Ø°ÙˆÙØ©
                    'kept': valid_ar[:5]
                })

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        if category.get('search_key_words_en'):
            original_en = category['search_key_words_en']

            valid_en = []
            invalid_en = []

            for kw in original_en:
                # Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù†ØªØ³Ø§Ù‡Ù„ Ø£ÙƒØ«Ø±
                kw_lower = kw.lower()
                name_en_lower = name_en.lower()

                # ØªØ­Ù‚Ù‚ Ø¨Ø³ÙŠØ·
                if any(word.lower() in kw_lower or kw_lower in word.lower()
                       for word in words_en if len(word) > 2):
                    valid_en.append(kw)
                elif kw_lower in name_en_lower or name_en_lower in kw_lower:
                    valid_en.append(kw)
                else:
                    invalid_en.append(kw)

            category['search_key_words_en'] = valid_en

            total_kept_en += len(valid_en)
            total_removed_en += len(invalid_en)

    print(f"\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚:")
    print(f"   ÙƒÙ„Ù…Ø§Øª Ø¹Ø±Ø¨ÙŠØ©:")
    print(f"     - Ù…Ø­ÙÙˆØ¸Ø©: {total_kept_ar}")
    print(f"     - Ù…Ø­Ø°ÙˆÙØ©: {total_removed_ar}")
    print(f"   ÙƒÙ„Ù…Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©:")
    print(f"     - Ù…Ø­ÙÙˆØ¸Ø©: {total_kept_en}")
    print(f"     - Ù…Ø­Ø°ÙˆÙØ©: {total_removed_en}\n")

    # Ø¹Ø±Ø¶ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©
    if issues:
        print(f"âš ï¸  ØªÙ†Ø¨ÙŠÙ‡: ÙˆØ¬Ø¯Øª {len(issues)} ØªØµÙ†ÙŠÙØ§Øª ØªÙ… Ø­Ø°Ù Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† ÙƒÙ„Ù…Ø§ØªÙ‡Ø§\n")
        print("Ø£ÙˆÙ„ 5 Ø­Ø§Ù„Ø§Øª:")
        for issue in issues[:5]:
            print(f"\n   ID: {issue['id']} - {issue['name_ar']}")
            print(f"   Ù…Ø­Ø°ÙˆÙØ©: {', '.join(issue['removed'])}")
            print(f"   Ù…Ø­ÙÙˆØ¸Ø©: {', '.join(issue['kept']) if issue['kept'] else 'Ù„Ø§ ØªÙˆØ¬Ø¯'}")

    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø¸ÙŠÙ
    print(f"\nğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ù†Ø¸Ù...")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"âœ… ØªÙ…! Ø­ÙÙØ¸ ÙÙŠ: {output_file}\n")

    # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø§Øª
    print("ğŸ“‹ Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:\n")
    for i in [0, 100, 200]:
        if i < len(data):
            cat = data[i]
            print(f"   {cat['name_ar']}")
            print(f"   - Ø¹Ø±Ø¨ÙŠ ({len(cat.get('search_key_words_ar', []))}): {', '.join(cat.get('search_key_words_ar', [])[:3])}...")
            print()

if __name__ == '__main__':
    input_file = r'f:\category and subcategory\categories_complete.json'
    output_file = r'f:\category and subcategory\categories_validated.json'

    validate_and_clean_keywords(input_file, output_file)

    print("=" * 70)
    print("ğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ Ø¨Ù†Ø¬Ø§Ø­!")
    print("=" * 70)
